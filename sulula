#!/usr/bin/env python3
# encoding=UTF-8

# Copyright Â© 2017-2022 Jakub Wilk <jwilk@jwilk.net>
# SPDX-License-Identifier: MIT

import argparse
import datetime
import getpass
import http.cookiejar
import math
import re
import shutil
import sys
import urllib.request

import lxml.html
import yaml

type(0_0)  # Python >= 3.6 is required

prog = argparse.ArgumentParser().prog

class UserAgent():

    ident = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) Gecko/20100101 Firefox/102.0'
    logging = None

    def __init__(self, *, host):
        cookie_jar = http.cookiejar.CookieJar()
        cookie_proc = urllib.request.HTTPCookieProcessor(cookie_jar)
        self.opener = urllib.request.build_opener(cookie_proc)
        self.base_url = f'https://{host}/'
        self.headers = {
            'User-Agent': self.ident,
            'Accept-Language': 'en-US,en;q=0.5',
        }

    def _request(self, url, *, data):
        url = urllib.parse.urljoin(self.base_url, url)
        if self.logging is not None:
            print('#', url, file=self.logging)
        request = urllib.request.Request(
            url,
            headers=self.headers,
            data=data,
        )
        with self.opener.open(request) as response:
            return response.read()

    def get(self, url):
        return self._request(url, data=None)

    def post(self, url, *, data):
        return self._request(url, data=data)

def parse_html(s):
    html_parser = lxml.html.HTMLParser(encoding='UTF-8')
    return lxml.html.document_fromstring(s, parser=html_parser)

def parse_date(s, *, regexp):
    def repl(match):
        s = match.group(0)
        c = match.group(1)
        regexp = dict(
            y='[0-9]{4}',
            m='[01][0-9]',
            d='[0-3][0-9]',
        )[c]
        return s[:-1] + regexp + s[-1]
    regexp = regexp0 = re.sub(r'[(][?]P<([ydm])>[)]', repl, regexp)
    regexp = re.compile(rf'\A(?:){regexp}\Z', re.DOTALL)
    match = regexp.match(s)
    if match is None:
        raise ValueError(f'{s!r} does not match {regexp0!r}')
    ymd = [int(match.group(k)) for k in ('y', 'm', 'd')]
    return datetime.date(*ymd)

def main():
    ap = argparse.ArgumentParser()
    if sys.version_info < (3, 10):
        # https://bugs.python.org/issue9694
        ap._optionals.title = 'options'
    ap.add_argument('--host', metavar='HOST', required=True)
    ap.add_argument('--user', metavar='USER', required=True)
    ap.add_argument('--password-file', metavar='FILE', help='read password from FILE')
    ap.add_argument('--with-returned', action='store_true')
    ap.add_argument('--verbose', action='store_true')
    options = ap.parse_args()
    host = options.host
    if '.' not in options.host:
        host = f'{host}.sowa.pl'
    if options.password_file is not None:
        with open(options.password_file, 'rt') as file:
            password = file.readline()
        password = password.rstrip('\n')
    else:
        password = getpass.getpass(f'{options.user} password for {host}: ')
    if not password:
        print(f'{prog}: error: empty password', file=sys.stderr)
        sys.exit(1)
    user = options.user
    ua = UserAgent(host=host)
    if options.verbose:
        ua.logging = sys.stderr
    url_tmpl = '/sowacgi.php?KatID=0&typ=acc&id={page}'
    url = url_tmpl.format(page='info')
    data = ua.get(url)
    html = parse_html(data)
    elts = html.xpath('//div[@id="simple-offline"]')
    if elts:
        [elt] = elts
        text = elt.text_content().strip()
        print(f'{prog}: server error: {text}', file=sys.stderr)
        sys.exit(1)
    [form] = html.xpath('//form[@name="log"]')
    form.inputs['swww_user'].value = user
    form.inputs['swww_pass'].value = password
    form_data = form.form_values()
    form_data = urllib.parse.urlencode(form_data)
    form_data = form_data.encode('ASCII')
    data = {}
    tsize = shutil.get_terminal_size(fallback=(math.inf, math.inf))
    def flush_data():
        yaml.dump(data,
            stream=sys.stdout,
            sort_keys=False,
            allow_unicode=True,
            width=(tsize.columns - 6)
        )
        data.clear()
    need_logout = True
    html = ua.post(form.action, data=form_data)
    try:
        html = parse_html(html)
        elts = html.xpath('//div[@class="error-msg"]')
        if elts:
            [elt] = elts
            text = elt.text_content().strip()
            if text.startswith('Login '):
                need_logout = False
                print(f'{prog}: error: could not log in', file=sys.stderr)
                sys.exit(1)
        [elt] = html.xpath('//div[@id="acc-info-barcode-no"]')
        data['card-no'] = elt.text.strip()
        [elt] = html.xpath('//div[@id="acc-info-cardno"]')
        text = elt.text_content()
        data['valid-through'] = parse_date(text, regexp=r'.*\bvalid\s+to\s+(?P<d>)[.](?P<m>)[.](?P<y>)\b.*')
        [elt] = html.xpath('//div[@id="acc-info-data-name"]')
        data['name'] = elt.text.strip()
        [elt] = html.xpath('//div[@id="acc-info-data-birthday"]/div[last()]')
        data['birth-date'] = parse_date(elt.text.strip(), regexp=r'(?P<y>)-(?P<m>)-(?P<d>)')
        [elt] = html.xpath('//div[@id="acc-info-data-main-addr"]/div[last()]')
        text = [line.strip() for line in elt.text.strip().splitlines()]
        data['home-address'] = text
        [elt] = html.xpath('//div[@id="acc-info-data-phone"]/div[last()]')
        data['phone'] = elt.text.strip()
        [elt] = html.xpath('//div[@id="acc-info-addr-items"]//div[@class="acc-info-protected"]')
        data['email'] = elt.text.strip()
        [elt] = html.xpath('//div[@id="acc-info-summary-items"]/div[last()]/b')
        text = elt.text.strip()
        assert text.count('.') == 0
        assert text.count(',') == 1
        text = text.replace(',', '.')
        data['balance'] = text
        flush_data()
        for page in 'onloan', 'reserved', 'returned':
            if page == 'returned' and not options.with_returned:
                continue
            key = re.sub('^on', 'on-', page)
            items = data[key] = []
            url = url_tmpl.format(page=page)
            html = ua.get(url)
            html = parse_html(html)
            record_elts = html.xpath('//div[@data-recid]')
            for record_elt in record_elts:
                item = {}
                items += [item]
                [elt] = record_elt.xpath('.//span[@class="desc-o-title"]')
                item['title'] = str(elt.text_content())
                [elt] = record_elt.xpath('.//div[@class="record-thumb"]//div[@title="Open the page for this record"]')
                match = re.search(r"'(https://[^\s']+)'", elt.get('onclick', ''))
                if match is not None:
                    item['url'] = match.group(1)
                [elt] = record_elt.xpath('.//div[@data-agenda]/*[@class="acct-agenda"]')
                item['agenda'] = elt.text
                elts = record_elt.xpath('.//div[@data-agenda]/span[@class="acct-date"]')
                for key, elt in zip(('from', 'to'), elts):
                    key = 'date-' + key
                    text = elt.text.strip()
                    item[key] = parse_date(text, regexp=r'(?P<d>)[.](?P<m>)[.](?P<y>)')
                if page == 'reserved':
                    [elt] = record_elt.xpath('.//div[@data-agenda]/span[@class="acct-rezdate"]')
                    text = elt.text.strip()
                    item['request-date'] = parse_date(text, regexp=r'(?P<d>)[.](?P<m>)[.](?P<y>)\s.*')
                    elts = record_elt.xpath('.//span[@class="acct-ready"]')
                    if elts:
                        text = elts[0].text or ''
                        if re.search(r'\bnot ready for pick up\b', text):
                            item['ready'] = False
                        elif re.search(r'\bis READY to pick up\b', text):
                            item['ready'] = True
                        elif re.search(r'\bis ready for delivery\b', text):
                            item['ready'] = 'for-delivery'
                    elts = record_elt.xpath('.//span[@class="acct-isfirst" or @class="acct-isnth"]')
                    if elts:
                        [elt] = elts
                        match = re.match(r'\bYou are in the (\d+) place in the queue\b', elt.text)
                        n = int(match.group(1))
                        item['queue-pos'] = n
                if page == 'onloan':
                    elts = record_elt.xpath('.//span[@class="acc-waiting-number"]')
                    if elts:
                        [elt] = elts
                        match = re.match(r'^(\d+) p', elt.text)
                        n = int(match.group(1))
                        item['queue-len'] = n
            flush_data()
    finally:
        if need_logout:
            url = url_tmpl.format(page='logout')
            ua.get(url)

if __name__ == '__main__':
    main()

# vim:ts=4 sts=4 sw=4 et
